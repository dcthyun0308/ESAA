{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIb+HAwHBb21uyPVA6YovJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcthyun0308/ESAA/blob/main/ESAA_YB_week13_2_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **웹 기사 추천 AI 경진대회**\n",
        "\n",
        "**1. 주제 및 데이터**\n",
        "\n",
        "- 웹 기사 조회 로그 데이터를 활용해 사용자에게 적합한 기사를 추천하는 AI 알고리즘 개발\n",
        "\n",
        "- 데이터 : view_log.csv(훈련용 train 데이터, 유저가 어던 기사를 조회했는지 기록된 로그), article_info.csv(기사 정보-제목,본문,언어,형식 등), sample_submission.csv(제출양식)\n",
        "\n",
        "**2. 코드 리뷰**\n",
        "\n",
        "EDA\n",
        "- 유저 행동 로그 통계 : 사용자 수 분포, 조회 빈도 분포, 기사별 조회 빈도, 지역/국가별 분포\n",
        "\n",
        "- 기사 특성 확인 : 제목/본문 텍스트 길이 분포, 언어별 분포, 기사 작성자와 조회자 분포\n",
        "\n",
        "전처리\n",
        "- 텍스트 기반 가중치 계산 - BM25 Weight : 기사 텍스트 임베딩 없이, BM25 기반 가중치를 계산하여 기사 간 유사도를 구함, implicit 패키지의 bm25_weight 함수를 이용\n",
        "\n",
        "모델링\n",
        "- Cosine Similaruty 기반 추천 : 기사 간 유사도를 Cosine Similarity로 계산, 유사도 기반 추천 방식\n",
        "\n",
        "- LMF : 행렬 분해 기반 모델, Latent factor를 이용하여 사용자와 기사 embedding을 학습 --> 차원 축소된 공간에서 추천 수행\n",
        "\n",
        "**3. 차별점 및 배운점**\n",
        "\n",
        "- BM25 Weight 도입 : 일반적으로 추천 시스템에서는 사용자-아이템 빈도 기반 접근이 많은데 정보 검색 기번(BM25)을 weighting에 활용함으로써 데이터를 효과적으로 재가중치했고, 실 성능 향상에 기여한 포인트임.\n",
        "\n",
        "- Content-implicit 융합 접근 : 단순 CF보다 BM25 + Cosine + Matrix Factorization 결합의 하이브리드\n",
        "\n",
        "- Baseline 극복 전략 : 베이스라인의 성능이 꽤 높은 추천 문제에서 단순 모델들보다 약하지만 효과적으로 향상할 수 있는 모델로 다듬은 점이 강점."
      ],
      "metadata": {
        "id": "pjiyt0CSmJ2w"
      }
    }
  ]
}